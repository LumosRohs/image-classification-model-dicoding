# -*- coding: utf-8 -*-
"""Image Classification Model Deployment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WDE6OdZUDQ4aoVPN3SKru_VjNda8HQdf

# Get data from kaggle
"""

from google.colab import drive
drive.mount('/content/drive')

! pip install kaggle

! mkdir ~/.kaggle

! cp /content/drive/MyDrive/Kaggle/kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download puneet6060/intel-image-classification

! unzip intel-image-classification.zip

"""# Library"""

import tensorflow as tf
from keras_preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import DenseNet201
from keras.layers import Input
from keras import layers
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import numpy as np
import matplotlib.pyplot as plt
import pathlib

"""# Data Preprocessing"""

train_dir = '/content/seg_train/seg_train'

"""## Image Generator"""

datagen = ImageDataGenerator(
    rescale=1/255.,
    rotation_range=30,
    shear_range=0.2,
    zoom_range=0.2,
    vertical_flip=True,
    fill_mode='nearest',
    validation_split=0.2
)

train_generator = datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150), 
    batch_size=32,
    shuffle=True,
    subset='training',
    class_mode='categorical'
)

validation_generator = datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    shuffle=False,
    subset='validation',
    class_mode='categorical'
)

train_generator.class_indices

validation_generator.class_indices

"""## Visualize dataset"""

class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']

x,y = validation_generator.next()

label = np.argmax(y, axis=1)
fig = plt.figure(figsize=(10,10))
fig.suptitle("images example in dataset", fontsize=16)
for i in range(16):
    plt.subplot(4,4,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(x[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[label[i]])
plt.show()

"""# Transfer Learning with DenseNet201"""

pre_trained_model = DenseNet201(weights='imagenet', include_top=False, input_tensor=Input(shape=(150, 150, 3)))

freeze_index = None
for i,layer in enumerate(pre_trained_model.layers):
    if 'conv4' in layer._name:
        freeze_index = i
        break
        
for layer in pre_trained_model.layers[:freeze_index]:
    layer.trainable = False

last_output = pre_trained_model.output
x = layers.GlobalAveragePooling2D()(last_output)
x = layers.Dense(512, activation='relu')(x)
outputs = layers.Dense(6, activation='softmax')(x)

model = tf.keras.models.Model(pre_trained_model.input, outputs)

model.summary()

num_epochs = 15
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# earlystopping = EarlyStopping(monitor='val_loss',min_delta = 0, patience = 5, verbose = 1, restore_best_weights=True)

learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', 
                                            patience=3, 
                                            verbose=1, 
                                            factor=0.3, 
                                            min_lr=0.00000001)

"""## Train Model"""

H = model.fit(train_generator,
              epochs=num_epochs,
              validation_data=validation_generator, callbacks=[learning_rate_reduction])

"""# Learning Plot"""

plt.style.use("ggplot")
plt.figure(figsize=(10, 5))
plt.plot(np.arange(0, 15), H.history["loss"], label="training")
plt.plot(np.arange(0, 15), H.history["val_loss"], label="validation")
plt.title("Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.figure(figsize=(10, 5))
plt.plot(np.arange(0, num_epochs), H.history["accuracy"], label="training")
plt.plot(np.arange(0, num_epochs), H.history["val_accuracy"], label="validation")
plt.title("Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

"""# Convert Model to TFLite"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('vegs.tflite')
tflite_model_file.write_bytes(tflite_model)